from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from transformers import BertForSequenceClassification, BertTokenizer
from faster_whisper import WhisperModel
import torch
import os
import uuid
import librosa
import soundfile as sf

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… Whisper Turbo ëª¨ë¸ ë¡œë“œ (faster-whisper)
whisper_model = WhisperModel("base", device="cuda" if torch.cuda.is_available() else "cpu", compute_type="float16")

# âœ… KoBERT ë¡œë“œ (Hugging Face ëª¨ë¸)
kobert_model = BertForSequenceClassification.from_pretrained("gdstorm/kobert-mvp")
kobert_tokenizer = BertTokenizer.from_pretrained("gdstorm/kobert-mvp")

kobert_model.eval()

@app.post("/analyze_audio")
async def analyze_audio(file: UploadFile = File(...), session_id: str = Form(...), duration_sec: str = Form(...)):
    temp_id = str(uuid.uuid4())
    input_aac = f"./temp_{temp_id}.aac"
    input_wav = f"./temp_converted.wav"

    with open(input_aac, "wb") as f:
        f.write(await file.read())

    # âœ… AAC â†’ WAV ë³€í™˜ (librosa + soundfile)
    try:
        audio, sr = librosa.load(input_aac, sr=16000)
        sf.write(input_wav, audio, sr, format="WAV")
    except Exception as e:
        return {"status": "error", "message": f"íŒŒì¼ ë³€í™˜ ì˜¤ë¥˜: {e}"}

    # âœ… Whisper Turbo ì „ì‚¬
    try:
        segments, _ = whisper_model.transcribe(input_wav, language="ko")
        transcription = "".join([seg.text for seg in segments])
    except Exception as e:
        return {"status": "error", "message": f"ì „ì‚¬ ì‹¤íŒ¨: {e}"}

    # âœ… KoBERT ë¶„ì„
    inputs = kobert_tokenizer(transcription, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = kobert_model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)
        confidence, predicted_label = torch.max(probs, dim=1)
        confidence = round(confidence.item(), 4)
        predicted_label = predicted_label.item()

    # âœ… ìœ ì°½ì„± ì ìˆ˜ (ë§ ì†ë„ ê¸°ì¤€)
    duration = float(duration_sec)
    word_count = len(transcription.strip().split())
    wpm = word_count / (duration / 60.0)
    fluency_score = round(wpm, 2)

    comment = f"ğŸ§  ì˜ˆì¸¡ëœ ì–¸ì–´ ì—°ë ¹: {predicted_label}ì„¸ (ì‹ ë¢°ë„: {round(confidence*100, 2)}%)"

    return {
        "status": "evaluated",
        "transcription": transcription,
        "predicted_label": predicted_label,
        "confidence": confidence,
        "fluency_score": fluency_score,
        "comment": comment
    }
